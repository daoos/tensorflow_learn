{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "import urllib2\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_file(file_name, writer_name, agree, comment, postings):\n",
    "    f = open(dictionary+file_name+'.txt', mode='w')\n",
    "    f.write(writer_name+'\\t'+agree+'\\t'+comment+'\\n')\n",
    "    f.write(postings)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    dictionary = './Qiubai/'\n",
    "    if not os.path.exists(dictionary):\n",
    "        os.mkdir(dictionary)\n",
    "    f_all = open(dictionary+'All.txt', mode='w')\n",
    "\n",
    "    for page in range(1, 100):\n",
    "        url = 'http://www.qiushibaike.com/hot/page/' + str(page)\n",
    "        headers = {'User-Agent':'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'}\n",
    "        # print url\n",
    "        try:\n",
    "            request = urllib2.Request(url, headers=headers)\n",
    "            response = urllib2.urlopen(request)\n",
    "            content = response.read().decode('utf-8')\n",
    "            print content\n",
    "            # content = requests.get(url)\n",
    "            # content = content.text.encode(content.encoding).decode('utf-8')\n",
    "            pattern = re.compile('<div class=\"author clearfix\">.*?<a href=\"/users/.*?/\".*?'\n",
    "                                 '<img src=\".*? alt=\"(.*?)\"/>.*?'\n",
    "                                 '<a href=\"/article/(.*?)\".*?<div class=\"content\">.*?<span>(.*?)</span>'\n",
    "                                 '.*?<span class=\"stats-vote\"><i class=\"number\">(.*?)</i>.*?</span>'\n",
    "                                 '.*?<span class=\"stats-comments\">.*?<a href=\"/article/.*?<i class=\"number\">(.*?)</i>',\n",
    "                                 re.S)\n",
    "            items = re.findall(pattern, content)\n",
    "            for i, item in enumerate(items):\n",
    "                postings = item[2].replace('<br/>', '\\n')\n",
    "                print '发帖人ID：', item[0]\n",
    "                print '帖子ID：', item[1]\n",
    "                print '内容：', postings\n",
    "                print '点赞：', item[3]\n",
    "                print '评论数：', item[4]\n",
    "                write_file(item[1], item[0], item[3], item[4], postings)\n",
    "                f_all.write(item[0])\n",
    "                f_all.write('\\n')\n",
    "                f_all.write(postings)\n",
    "                f_all.write('\\n\\n')\n",
    "        except urllib2.URLError, e:\n",
    "            if hasattr(e,\"code\"):\n",
    "                print e.code\n",
    "            if hasattr(e,\"reason\"):\n",
    "                print e.reason\n",
    "            break\n",
    "    f_all.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
