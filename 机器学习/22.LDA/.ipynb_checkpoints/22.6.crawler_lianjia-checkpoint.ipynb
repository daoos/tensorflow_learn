{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def not_empty(str):\n",
    "    return str and str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8dd969bc82d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdistricts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'data-role'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'ershoufang'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# <div data-role=\"ershoufang\">\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# soup.select()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdistrict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistricts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mdistrict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdistrict_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistrict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m   \u001b[0;31m# '东城', '西城', '朝阳', '海淀'......\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    url_main = 'http://bj.lianjia.com'\n",
    "\n",
    "    f = open(u'北京二手房.csv', 'wb')\n",
    "    f.write(unicode('\\xEF\\xBB\\xBF', 'utf-8'))   # 文件头\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['区域', '小区名称', '户型', '面积', '价格(万)', '单价(元/平米)',\n",
    "                     '性质', '朝向', '装修', '是否有电梯', '楼层', '建筑年代', '楼型'])\n",
    "    res = requests.get('http://bj.lianjia.com/ershoufang')\n",
    "    res = res.text.encode(res.encoding).decode('utf-8')\n",
    "    soup = BeautifulSoup(res, 'html.parser')\n",
    "    # print soup.prettify()\n",
    "    districts = soup.find(name='div', attrs={'data-role':'ershoufang'}) # <div data-role=\"ershoufang\">\n",
    "    # soup.select()\n",
    "    for district in districts.find_all(name='a'):\n",
    "        print district['title']\n",
    "        district_name = district.text   # '东城', '西城', '朝阳', '海淀'......\n",
    "        url = '%s%s' % (url_main, district['href'])\n",
    "        # print url\n",
    "        res = requests.get(url)\n",
    "        res = res.text.encode(res.encoding).decode('utf-8')\n",
    "        soup = BeautifulSoup(res,'html.parser')\n",
    "        # print soup.prettify()\n",
    "        page = soup.find('div', {'class':'page-box house-lst-page-box'})\n",
    "        if not page:    # 平谷区没有房源，直接返回\n",
    "            continue\n",
    "        total_pages = dict(eval(page['page-data']))['totalPage']    # 总页数\n",
    "        # print total_pages\n",
    "        for j in range(1, total_pages+1):\n",
    "            url_page = '%spg%d/' % (url, j)\n",
    "            res = requests.get(url_page)\n",
    "            res = res.text.encode(res.encoding).decode('utf-8')\n",
    "            soup = BeautifulSoup(res, 'html.parser')\n",
    "            # print soup.prettify()\n",
    "            sells = soup.find(name='ul', attrs={'class':'sellListContent', 'log-mod':'list'})\n",
    "            if not sells:\n",
    "                continue\n",
    "            # <a class=\"title\" data-bl=\"list\" data-el=\"ershoufang\" data-log_index=\"1\" href=\"XX\" target=\"_blank\">\n",
    "            titles = soup.find_all(name='a', attrs={'class':'title', 'data-bl':'list', 'data-el':'ershoufang'})\n",
    "            # <a data-el=\"region\" data-log_index=\"1\" href=\"X\" target=\"_blank\">\n",
    "            regions = sells.find_all(name='a', attrs={'data-el':'region'})\n",
    "            infos = sells.find_all(name='div', class_='houseInfo')      # <div class=\"houseInfo\">\n",
    "            infos2 = sells.find_all(name='div', class_='positionInfo')  # <div class=\"positionInfo\">\n",
    "            prices = sells.find_all(name='div', class_='totalPrice')    # <div class=\"totalPrice\">\n",
    "            unit_prices = sells.find_all(name='div', class_='unitPrice') # <div class=\"unitPrice\" data-hid=\"X\" data-price=\"X\" data-rid=\"X\">\n",
    "            subways = sells.find_all(name='span', class_='subway')    # <span class=\"subway\">\n",
    "            taxs = sells.find_all(name='span', class_='taxfree')      # <span class=\"taxfree\">\n",
    "            N = max(len(titles), len(regions), len(prices), len(unit_prices), len(subways), len(taxs), len(infos), len(infos2))\n",
    "            # for title, region, price, unit_price, subway, tax, info, info2 in zip(titles, regions, prices, unit_prices, subways, taxs, infos, infos2):\n",
    "            for i in range(N):\n",
    "                room_type = area = orientation = decoration = elevator = floor = year = slab_tower = None\n",
    "                title = titles[i] if len(titles) > i else None\n",
    "                region = regions[i] if len(regions) > i else None\n",
    "                price = prices[i] if len(prices) > i else None\n",
    "                unit_price = unit_prices[i] if len(unit_prices) > i else None\n",
    "                subway = subways[i] if len(subways) > i else None\n",
    "                tax = taxs[i] if len(taxs) > i else None\n",
    "                info = infos[i] if len(infos) > i else None\n",
    "                info2 = infos2[i] if len(infos2) > i else None\n",
    "                if title:\n",
    "                    print 'Title: ', title.text\n",
    "                if region:\n",
    "                    region = region.text\n",
    "                if price:\n",
    "                    price = price.text\n",
    "                    price = price[:price.find('万')]\n",
    "                if unit_price:\n",
    "                    unit_price = unit_price.span.text.strip()\n",
    "                    unit_price = unit_price[:unit_price.find('元/平米')]\n",
    "                    if unit_price.find('单价') != -1:\n",
    "                        unit_price = unit_price[2:]\n",
    "                if subway:\n",
    "                    subway = subway.text.strip()\n",
    "                if tax:\n",
    "                    tax = tax.text.strip()\n",
    "                if info:\n",
    "                    info = info.text.split('|')\n",
    "                    room_type = info[1].strip()     # 几室几厅\n",
    "                    area = info[2].strip()          # 房屋面积\n",
    "                    area = area[:area.find('平米')]\n",
    "                    orientation = info[3].strip().replace(' ', '')   # 朝向\n",
    "                    decoration = '-'\n",
    "                    if len(info) > 4:       # 如果是车位，则该项为空\n",
    "                        decoration = info[4].strip()    # 装修类型：简装、中装、精装、豪装、其他\n",
    "                    elevator = '无'\n",
    "                    if len(info) > 5:\n",
    "                        elevator = info[5].strip()      # 是否有电梯：有、无\n",
    "                if info2:\n",
    "                    info2 = filter(not_empty, info2.text.split(' '))\n",
    "                    floor = info2[0].strip()\n",
    "                    info2 = info2[1]\n",
    "                    year = info2[:info2.find('年')]\n",
    "                    slab_tower = info2[info2.find('建')+1:]\n",
    "                print district_name, region, room_type, area, price, unit_price, tax, orientation, decoration, elevator, floor, year, slab_tower\n",
    "                writer.writerow([district_name, region, room_type, area, price, unit_price, tax, orientation, decoration, elevator, floor, year, slab_tower])\n",
    "                # break\n",
    "            # break\n",
    "        # break\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
